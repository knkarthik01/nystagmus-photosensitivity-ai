# ğŸ“ˆ AI Solutions for Nystagmus Patients with Photosensitivity

![License: Apache 2.0](https://img.shields.io/badge/License-Apache_2.0-blue.svg)

## Overview
This project develops an AI-driven system to predict photosensitivity risk and recommend real-time visual adaptations for patients suffering from **Nystagmus** with **photosensitivity** issues.

By analyzing **environmental images** and **eye movement patterns**, the model forecasts high-risk scenarios and suggests optimal filter adaptations to improve patient quality of life.

---

## ğŸ—ï¸ Project Structure

```
nystagmus-photosensitivity-ai/
â”œâ”€â”€ data/                     # Synthetic datasets and preprocessing scripts
â”œâ”€â”€ models/                   # Dual-branch CNN architecture and training scripts
â”œâ”€â”€ visualization/            # GradCAM and risk zone visualizations
â”œâ”€â”€ recommendation_engine/    # Adaptive filter recommendation system
â”œâ”€â”€ demo/                     # Demo application
â”œâ”€â”€ project_tests/            # Unit tests for core modules (safe naming)
â”œâ”€â”€ docs/                     # ACM paper materials
â”œâ”€â”€ notebooks/                # Colab/Notebook workflows
â”œâ”€â”€ presentation/             # Slides and recorded presentation
â”œâ”€â”€ requirements.txt          # Project dependencies
â””â”€â”€ README.md                  # This file
```

---

## ğŸš€ Quick Start

1. **Clone this repository**:
   ```bash
   git clone https://github.com/knkarthik01/nystagmus-photosensitivity-ai.git
   cd nystagmus-photosensitivity-ai
   ```

2. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

3. **Run notebooks** (Google Colab recommended):
   - `notebooks/0_get_started.ipynb` â†’ Setup environment
   - `notebooks/1_data_preprocessing.ipynb` â†’ Generate synthetic dataset
   - `notebooks/2_model_training.ipynb` â†’ Train model and save
   - `notebooks/3_explainability.ipynb` â†’ SHAP-based explainability

4. **Run all project tests**:
   ```bash
   python project_tests/run_all_tests.py
   ```

**Note**:  End to End model implementation is available in [model_implementation_end_to_end.ipynb](https://github.com/knkarthik01/nystagmus-photosensitivity-ai/blob/main/model_implementation_end_to_end.ipynb)   â†’ Provides Visibility of end to end in notebook (Google Colab)

---

## ğŸ“š Working with Notebooks

### Setting up Environment
- Always run **`0_get_started.ipynb`** first to install dependencies.

### Workflow Order
| Step | Notebook | Purpose |
|:---|:---|:---|
| 1 | `1_data_preprocessing.ipynb` | Generate synthetic dataset |
| 2 | `2_model_training.ipynb` | Train model and save weights |
| 3 | `3_explainability.ipynb` | SHAP explainability on test set |

> âš¡ **Tip:** Clear outputs before uploading to GitHub for clean rendering.

---

### Model Architecture
Our dual-branch neural network processes both brightness levels and eye movement variance:

#### Brightness Branch

Processes environmental brightness information
Feature extraction through multiple dense layers
Outputs a 32-dimensional feature vector

#### Eye Movement Branch

Processes eye movement variance signals
Parallel feature extraction
Outputs a 32-dimensional feature vector

#### Fusion Module

Concatenates features from both branches (64 features total)
Applies dropout for regularization
Final sigmoid activation for risk prediction (0-1)

#### Data Generation
Our project uses both real and synthetic data:
Synthetic Dataset

Brightness levels: 100-1000 lux (indoor to bright outdoor)
Eye movement variance: 0-10 (stable to severe nystagmus)
Risk scores: Generated using a probabilistic model with noise

#### Explainability
Our system uses SHAP (SHapley Additive exPlanations) to provide transparent explanations for model predictions:
SHAP Analysis

Explains how each feature contributes to risk prediction
Identifies whether brightness or eye movement has more impact
Creates visualizations for patient and clinician understanding

#### Recommendation Engine
Our system provides personalized filter recommendations based on environmental factors and user preferences:

 #### Base Recommendation System

Analyzes brightness levels and eye movement patterns
Recommends appropriate filters (Dark Amber, Cool Grey, Light Grey, etc.)
Provides explanatory notes with each recommendation

#### Personalized Recommendations

Adapts to user preferences over time
Accounts for personal sensitivity levels
Adjusts filter types (warmer/cooler) based on feedback
Modifies intensity based on user comfort

#### Web Demo (Local)
We provide a web-based demo using Streamlit:
Running the Web Demo

#### Install Streamlit:
pip install streamlit

#### (Optional)Launch the demo:
streamlit run demo/web_demo.py

Open your browser to the URL displayed in the terminal (typically http://localhost:8501)



## ğŸ§ª Testability

This project includes fully integrated **testability** across core modules:

- `project_tests/test_model.py` â†’ Model forward pass and dummy training
- `project_tests/test_recommendation.py` â†’ Recommendation system unit tests
- `project_tests/test_cli.py` â†’ CLI application behavior test

Run all tests from the project root:
```bash
python project_tests/run_all_tests.py
```

## ğŸ§ª Full Testing Guide

For detailed testing instructions, see [TESTING.md](./TESTING.md).

---

âœ… Ensures model, recommendation engine, and CLI app work reliably.

---

## ğŸ“‚ Important Notes
- **CSV Handling**:  
   - After generating `preprocessed_data.csv`, **download and upload manually** to GitHub under `/data/preprocessed/` if needed.
- **CLI Assumptions**:  
   - Ensure model (`dual_branch_cnn.pth`) is trained and available.
- **Colab Usage**:  
   - Save copies to Drive if metadata issues occur when syncing with GitHub.

---

## ğŸ“Š Key Features

- ğŸ§  **Dual-Branch CNN**: Processes environmental brightness + eye movement variance
- ğŸ”¥ **Explainable AI**: SHAP and GradCAM visualizations
- ğŸ§© **Recommendation Engine**: Suggests optimal filters dynamically
- ğŸ¯ **Synthetic Data Generator**: Flexible experiments and controlled testing

---

## ğŸ“š Technologies Used
- Python
- PyTorch
- SHAP / GradCAM
- Google Colab
- Git & GitHub

---

## ğŸ› ï¸ Future Directions
- Integration with wearable smart glasses
- Reinforcement learning for adaptive recommendations
- Expansion using real-world clinical datasets

---

## ğŸ“„ License
This project is licensed under the [Apache License](LICENSE).

---

## ğŸ‘¨â€ğŸ’» Project by
Karthik Prabhakar | [GitHub Profile](https://github.com/knkarthik01)
